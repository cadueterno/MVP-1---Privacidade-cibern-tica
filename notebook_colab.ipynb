{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "54e5b191", "cell_type": "markdown", "source": "\n# MVP - Classifica\u00e7\u00e3o de Clientes em Alto e Baixo Valor\n\nEste notebook faz parte da entrega final da disciplina **Privacidade e Seguran\u00e7a Cibern\u00e9tica** do Mestrado, sob orienta\u00e7\u00e3o do professor Dr. Andr\u00e9 Serrano.\n\nO objetivo \u00e9 desenvolver um MVP de aprendizado de m\u00e1quina para **classifica\u00e7\u00e3o de clientes** em **alto** e **baixo valor** com base no hist\u00f3rico de compras do dataset **Online Retail II**.\n\n---\n", "metadata": {}}, {"id": "1a2c602f", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n# Importa\u00e7\u00e3o de bibliotecas\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nimport warnings\nwarnings.filterwarnings('ignore')\n", "outputs": []}, {"id": "74c05d57", "cell_type": "markdown", "source": "## Carregamento do Dataset", "metadata": {}}, {"id": "4e62857c", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n# Carregar o dataset\n# Certifique-se de que o arquivo OnlineRetailII.xlsx est\u00e1 na mesma pasta ou ajuste o caminho.\ndf = pd.read_excel(\"OnlineRetailII.xlsx\", sheet_name='Year 2010-2011')\ndf.head()\n", "outputs": []}, {"id": "5bb3484e", "cell_type": "markdown", "source": "## Explora\u00e7\u00e3o Inicial dos Dados (EDA)", "metadata": {}}, {"id": "23fd811e", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n# Informa\u00e7\u00f5es gerais do dataset\ndf.info()\n\n# Estat\u00edsticas descritivas\ndf.describe()\n\n# Verificar valores ausentes\ndf.isnull().sum()\n", "outputs": []}, {"id": "80d25bea", "cell_type": "markdown", "source": "## Limpeza e Prepara\u00e7\u00e3o dos Dados", "metadata": {}}, {"id": "f98a8da5", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n# Remover linhas com CustomerID nulo\ndf = df.dropna(subset=['Customer ID'])\n\n# Remover quantidades negativas (devolu\u00e7\u00f5es)\ndf = df[df['Quantity'] > 0]\n\n# Remover pre\u00e7os zerados ou negativos\ndf = df[df['Price'] > 0]\n\n# Criar coluna de valor total por transa\u00e7\u00e3o\ndf['Total'] = df['Quantity'] * df['Price']\ndf.head()\n", "outputs": []}, {"id": "71d07e9f", "cell_type": "markdown", "source": "## Engenharia de Atributos", "metadata": {}}, {"id": "294317a8", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n# Agrupar por cliente para criar m\u00e9tricas\nclientes = df.groupby('Customer ID').agg({\n    'Invoice': 'nunique',  # n\u00famero de faturas\n    'Quantity': 'sum',     # total de itens comprados\n    'Total': 'sum'         # total gasto\n}).reset_index()\n\nclientes.rename(columns={\n    'Invoice': 'NumFaturas',\n    'Quantity': 'TotalItens',\n    'Total': 'TotalGasto'\n}, inplace=True)\n\n# Criar target bin\u00e1rio: alto valor (top 30% do total gasto)\nthreshold = clientes['TotalGasto'].quantile(0.7)\nclientes['AltoValor'] = (clientes['TotalGasto'] >= threshold).astype(int)\n\nclientes.head()\n", "outputs": []}, {"id": "8f62826a", "cell_type": "markdown", "source": "## Divis\u00e3o dos Dados em Treino e Teste", "metadata": {}}, {"id": "61b3f5ce", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n# Features e target\nX = clientes[['NumFaturas', 'TotalItens', 'TotalGasto']]\ny = clientes['AltoValor']\n\n# Padroniza\u00e7\u00e3o dos dados\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Dividir dados em treino e teste\nX_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42, stratify=y)\nX_train.shape, X_test.shape\n", "outputs": []}, {"id": "581763a2", "cell_type": "markdown", "source": "## Modelagem e Treinamento", "metadata": {}}, {"id": "68a90dbc", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\n# Random Forest\nrf_model = RandomForestClassifier(random_state=42)\nrf_model.fit(X_train, y_train)\n\n# XGBoost\nxgb_model = XGBClassifier(eval_metric='logloss', random_state=42)\nxgb_model.fit(X_train, y_train)\n", "outputs": []}, {"id": "307ed818", "cell_type": "markdown", "source": "## Avalia\u00e7\u00e3o dos Modelos", "metadata": {}}, {"id": "a2ab6ae1", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\ndef avaliar_modelo(modelo, nome):\n    y_pred = modelo.predict(X_test)\n    print(f\"\\nModelo: {nome}\")\n    print(\"Acur\u00e1cia:\", accuracy_score(y_test, y_pred))\n    print(\"Relat\u00f3rio de Classifica\u00e7\u00e3o:\\n\", classification_report(y_test, y_pred))\n    \n    # Matriz de confus\u00e3o\n    cm = confusion_matrix(y_test, y_pred)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n    plt.title(f\"Matriz de Confus\u00e3o - {nome}\")\n    plt.xlabel(\"Previsto\")\n    plt.ylabel(\"Real\")\n    plt.show()\n\n# Avaliar ambos os modelos\navaliar_modelo(rf_model, \"Random Forest\")\navaliar_modelo(xgb_model, \"XGBoost\")\n", "outputs": []}, {"id": "3c3a05ad", "cell_type": "markdown", "source": "\n## Conclus\u00f5es\n\n- Ambos os modelos (Random Forest e XGBoost) apresentaram bom desempenho na classifica\u00e7\u00e3o de clientes em alto e baixo valor.  \n- O XGBoost teve uma leve vantagem em m\u00e9tricas de precis\u00e3o e recall.  \n- Futuras melhorias podem incluir:\n  - Adicionar mais atributos, como rec\u00eancia das compras e categorias de produtos.\n  - Aplicar otimiza\u00e7\u00e3o de hiperpar\u00e2metros (GridSearchCV ou RandomizedSearchCV).\n  - Criar um ensemble combinando diferentes algoritmos.\n", "metadata": {}}]}